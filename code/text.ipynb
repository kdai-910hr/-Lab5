{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykVQATMCQgcu",
        "outputId": "171e9b37-1db0-4101-d1fd-4fbe4305a169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n",
            "/content/Lab5\n"
          ]
        }
      ],
      "source": [
        "# CoLab 上挂载云盘，本地的话不需要做这一步\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "FOLDERNAME = \"人工智能/Lab5\"\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "%cd drive/My\\ Drive\n",
        "%cp -r $FOLDERNAME ../../\n",
        "%cd ../../Lab5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s8q022HGvK-",
        "outputId": "eefa2285-717e-4a2d-afe5-1e4001be5497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.21)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.7.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gACJOwzdQMYE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import torch                    \n",
        "import torchvision\n",
        "import time\n",
        "import datetime\n",
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2NlIFM00RV0n"
      },
      "outputs": [],
      "source": [
        "data_path = \"data/\"\n",
        "train_path = \"train.txt\"\n",
        "test_path = \"test_without_label.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fyO3IL2lRmOI"
      },
      "outputs": [],
      "source": [
        "def tag2label(tag):\n",
        "    if tag == \"negative\": return 0\n",
        "    elif tag == \"neutral\": return 1\n",
        "    else: return 2\n",
        "\n",
        "def get_label_dict(path):  # 从 train.txt 读取作为训练集的序号\n",
        "  with open(path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    lines = [line.strip() for line in lines[1:]]\n",
        "  dict_ = {}\n",
        "  for line in lines:\n",
        "    raw_data = line.split(\",\")\n",
        "    dict_[raw_data[0]] = tag2label(raw_data[1])\n",
        "  return dict_\n",
        "\n",
        "def get_test_text(path):  # 从 test_without_labels.txt 读取作为测试集的序号\n",
        "  with open(path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    lines = [line.strip() for line in lines[1:]]\n",
        "  return [line.split(\",\")[0] for line in lines]\n",
        "\n",
        "  def get_text(path):   # 读取特定序号的文本数据\n",
        "    with open(path, 'r', errors='ignore') as f:\n",
        "        line = f.readline()\n",
        "    return line.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x7_N5nWVRoG8"
      },
      "outputs": [],
      "source": [
        "label_dict = get_label_dict(train_path)\n",
        "label_dict_keys = list(label_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oSEK26fzZyEN"
      },
      "outputs": [],
      "source": [
        "test_list = get_test_text(test_path)\n",
        "test_data = [['id', 'text']]\n",
        "for id_ in test_list:\n",
        "  test_data.append([int(id_), get_text(data_path+id_+\".txt\")])\n",
        "test_data = pd.DataFrame(test_data[1:], columns=test_data[0])   # 测试集数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W1IfOu7a8Gf",
        "outputId": "622463e2-f864-4889-aa50-c2672a698c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       id                                               text\n",
            "0       8  Energetic training today with our San Antonio ...\n",
            "1    1576  Let your voice be heard! 18+ #endsuicide #blit...\n",
            "2    2320  RT @Austin_Powers__: Shark Week would be so mu...\n",
            "3    4912             #TheTruthCaster http://t.co/S8jvqpKq5h\n",
            "4    3821  RT @jarpad: Hey #WBSDCC look what we're up to!...\n",
            "..    ...                                                ...\n",
            "506  1048        ??? #stunned #sunglasses #gafas #gafasdesol\n",
            "507  1059  Seeing @nbdbnb in a few days #excited #or #ter...\n",
            "508  1485  And the #dragon guarding our #heart is called ...\n",
            "509  3195  RT @NWSAlbuquerque: Isolated strong to severe ...\n",
            "510  2029  Cliff dwelling above Peacocks Gallop (recently...\n",
            "\n",
            "[511 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BtZSxJFXRvVW"
      },
      "outputs": [],
      "source": [
        "text_data = [['id', 'label', 'text']]\n",
        "for id_ in label_dict_keys:\n",
        "    try:\n",
        "        text_data.append([\n",
        "               int(id_), \n",
        "               int(label_dict[id_]), \n",
        "               get_text(data_path + id_ + \".txt\"), \n",
        "              ])\n",
        "    except: continue\n",
        "text_data = pd.DataFrame(text_data[1:], columns=text_data[0])       # 训练集数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3bnYpFZRvvI",
        "outputId": "dbe81c45-8a4c-41fb-bd80-bb3c02d9f593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of         id  label                                               text\n",
              "0     4597      0  RT @AmitSwami77: The conspirators have an evil...\n",
              "1       26      1  Waxwing trills, Chickadees calling \"here sweet...\n",
              "2     4383      0  @NYSE is looking a little despondent today...?...\n",
              "3      212      2  FERVENT | S,M,L | 140k free PLASTIC CLIP, keyc...\n",
              "4     2626      2  Nice day chilling in the park yesterday reliev...\n",
              "...    ...    ...                                                ...\n",
              "3995  3944      0  RT @IraqiSecurity: Car bomb in Aden Sq, Kadhim...\n",
              "3996   945      2  #Remember no one can make you #feel #inferior ...\n",
              "3997   695      2  RT @RapFavorites: Ye turned Valentine's Day in...\n",
              "3998  4874      0  RT @cybercuichi: Miracles and Faith have a hol...\n",
              "3999   246      0  RT @stoned_satan: https://t.co/y8SXRiJrP8 #cig...\n",
              "\n",
              "[4000 rows x 3 columns]>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data.describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZPpJDWBMtJC",
        "outputId": "45e0304d-b3c2-4799-dbea-599917f2e616"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mliang_kdai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z3m_dip4HjGQ"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dHmqDps4HmRW"
      },
      "outputs": [],
      "source": [
        "sentences = text_data.text.values\n",
        "labels = text_data.label.values\n",
        "test_sentences = test_data.text.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM9FpOsIH6iH",
        "outputId": "661834c2-f167-4382-9c38-21024c7e845d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  RT @AmitSwami77: The conspirators have an evil eye & are now set to physically attack Asaram Bapu Ji! #WeDemandSafety4Bapuji http://t.co/N8\n",
            "Token IDs: tensor([  101, 19387,  1030, 26445,  3215,  4213,  4328,  2581,  2581,  1024,\n",
            "         1996,  9530, 13102,  7895,  6591,  2031,  2019,  4763,  3239,  1004,\n",
            "         2024,  2085,  2275,  2000,  8186,  2886, 17306,  6444,  8670, 14289,\n",
            "        10147,   999,  1001, 21981, 16704,  5104, 10354, 27405,  2549,  3676,\n",
            "        14289,  4478,  8299,  1024,  1013,  1013,  1056,  1012,  2522,  1013,\n",
            "         1050,  2620,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Original:  Energetic training today with our San Antonio New Dollars/New Partners trainees\n",
            "Token IDs: tensor([  101, 18114,  2731,  2651,  2007,  2256,  2624,  4980,  2047,  6363,\n",
            "         1013,  2047,  5826, 26758,  2015,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "test_input_ids = []\n",
        "attention_masks = []\n",
        "test_attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True, # 添加 cls 与 sep\n",
        "                        max_length = 130,\n",
        "                        padding= \"max_length\",           # 使用 0-padding 统一长度\n",
        "                        return_attention_mask = True,   # 构建注意力以及掩码\n",
        "                        return_tensors = 'pt',     # 以 pytorch 的 tensor 类型返回\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "for sent in test_sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 130,\n",
        "                        padding= \"max_length\",\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Original: ', test_sentences[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39iiSnvdIuYs",
        "outputId": "b5f6d522-1405-4e41-ec5e-9f41b12ef5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3,600 training samples\n",
            "  400 validation samples\n"
          ]
        }
      ],
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks)\n",
        "\n",
        "# 测试集九一分出测试集与验证集\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(str(train_size) + \" training samples\")\n",
        "print(str(val_size) + \" validation samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e9YU2nngI0Mv"
      },
      "outputs": [],
      "source": [
        "def ret_dataloader():\n",
        "    batch_size = wandb.config.batch_size\n",
        "    print('batch_size = ', batch_size)\n",
        "    train_dataloader = DataLoader(train_dataset,\n",
        "                    sampler = RandomSampler(train_dataset), \n",
        "                    batch_size = batch_size)\n",
        "\n",
        "    validation_dataloader = DataLoader(val_dataset, \n",
        "                      sampler = SequentialSampler(val_dataset),   \n",
        "                      batch_size = batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, \n",
        "                    sampler = SequentialSampler(test_dataset),   \n",
        "                    batch_size = batch_size)\n",
        "    return train_dataloader,validation_dataloader, test_dataloader\n",
        "\n",
        "def ret_model():\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\", \n",
        "        num_labels = 3, \n",
        "        output_attentions = True, \n",
        "        output_hidden_states = True,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def ret_optim(model):\n",
        "    print('Learning_rate = ',wandb.config.learning_rate )\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr = wandb.config.learning_rate, \n",
        "                      eps = wandb.config.epsilon\n",
        "                    )\n",
        "    return optimizer\n",
        "\n",
        "def ret_scheduler(train_dataloader,optimizer):\n",
        "    epochs = wandb.config.epochs\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,           \n",
        "num_training_steps = total_steps)\n",
        "    return scheduler\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "qjKT9592I0KA",
        "outputId": "f1f45aa3-d74d-4bd3-948e-9ac3ca1db212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mliang_kdai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/Lab5/wandb/run-20220713_124103-11lkcz8q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/liang_kdai/multimodel_emotion_recognize/runs/11lkcz8q\" target=\"_blank\">text</a></strong> to <a href=\"https://wandb.ai/liang_kdai/multimodel_emotion_recognize\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/liang_kdai/multimodel_emotion_recognize/runs/11lkcz8q?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa1b6424950>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"multimodel_emotion_recognize\",\n",
        "      name=\"text\",\n",
        "      config={\"epochs\":10, \"batch_size\":16, \"learning_rate\":  2e-6, \"epsilon\": 1e-7})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XopOnsroI0EZ",
        "outputId": "e0aeed76-9582-4db6-f089-cb2b2d272a6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_size =  16\n",
            "Learning_rate =  2e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "model = ret_model()\n",
        "model.cuda()\n",
        "train_dataloader,validation_dataloader, test_dataloader = ret_dataloader()\n",
        "optimizer = ret_optim(model)\n",
        "scheduler = ret_scheduler(train_dataloader,optimizer)\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "epochs = wandb.config.epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQG9KTOwNzoB",
        "outputId": "3471e1ab-e769-4109-94f9-1a8ae1e58891"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTlZ7Kv0Iz_6",
        "outputId": "f01d7904-f77d-4fb8-fa37-0b251837013b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:10.\n",
            "Train  Accuracy: 0.58\n",
            "\n",
            "  Average training loss: 0.92\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.84\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.63\n",
            "\n",
            "  Average training loss: 0.84\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:14.\n",
            "Train  Accuracy: 0.68\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.71\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:59.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.73\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.74\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.75\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.76\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.76\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "Train  Accuracy: 0.77\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:14:13 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs): \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        output = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        wandb.log({'train_batch_loss':output.loss.item()})\n",
        "        total_train_loss += output.loss.item()\n",
        "        output.loss.backward()\n",
        "        quit()\n",
        "        logits = output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)  \n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader) \n",
        "    print(\"Train  Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    wandb.log({'avg_train_loss':avg_train_loss,'avg_train_acc':avg_train_accuracy})\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\\n  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\\n\".format(training_time))\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            output = model(b_input_ids, \n",
        "                  token_type_ids=None, \n",
        "                  attention_mask=b_input_mask,\n",
        "                  labels=b_labels)\n",
        "            \n",
        "        total_eval_loss += output.loss.item()\n",
        "        # 数值计算的时候需要将 cuda 的数据转回 cpu\n",
        "        logits = output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    wandb.log({'val_accuracy':avg_val_accuracy,'avg_val_loss':avg_val_loss})\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "torch.save(model, \"save_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fLyvyC1IIz7J"
      },
      "outputs": [],
      "source": [
        "# 使用模型对测试集的 txt 文本进行情感预测\n",
        "model1 = torch.load(\"save_model.pth\")\n",
        "preds = []\n",
        "model1.eval()\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  \n",
        "  with torch.no_grad():        \n",
        "      output = model1(b_input_ids, \n",
        "              token_type_ids=None, \n",
        "              attention_mask=b_input_mask)\n",
        "      output_ = output[0].cpu().numpy() # 同样需要先转成 cpu 才能继续计算\n",
        "      for i in output_:\n",
        "        preds.append(i.argmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQJEsNhwmcPP",
        "outputId": "110280a2-8346-45fb-a06b-3623e16aeec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2jPiKJWnoLhr"
      },
      "outputs": [],
      "source": [
        "def label2tag(label):\n",
        "  label = int(label)\n",
        "  if label == 0:  return \"negative\"\n",
        "  elif label == 1:  return \"neutral\"\n",
        "  else: return \"positive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_Zb5QtGknscJ"
      },
      "outputs": [],
      "source": [
        "with open('test_with_label.txt', 'w') as f:  # 输出预测结果\n",
        "  f.write(\"guid,tag\\n\")\n",
        "  for i in range(len(test_list)):\n",
        "    f.write(str(test_list[i])+\",\"+label2tag(preds[i])+\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21a303c8281a4e4083944b1fc7e72d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c2c576888aa43e8b1d661128c6becc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83659c81234e45c198b1529164d16b03",
            "placeholder": "​",
            "style": "IPY_MODEL_77ca062d4fbf447986023159a7716de7",
            "value": " 230M/230M [00:01&lt;00:00, 137MB/s]"
          }
        },
        "37dfd588a6d8489eb7698699cb13c764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9c7b9911814648820c1600e85a719f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b22b288b024493b40f8713681801ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "7644321972284fcabc17109951971908": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77172a9f89ef4cc489df933e7e149826": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ca062d4fbf447986023159a7716de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ba1408b4ea2486cba405df7b6f60af8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824129c6380d4facb3a4dd741241ee25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83659c81234e45c198b1529164d16b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c63711cfcff460398a7e4a5be6a3e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef53e30a01eb422086accebafce47bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_77172a9f89ef4cc489df933e7e149826",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "ae552726e3f24af2afe28cb6136cbbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824129c6380d4facb3a4dd741241ee25",
            "placeholder": "​",
            "style": "IPY_MODEL_4a9c7b9911814648820c1600e85a719f",
            "value": "Sanity Checking DataLoader 0:   0%"
          }
        },
        "b3b67399338b47109c3e8dd874c5c78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba1408b4ea2486cba405df7b6f60af8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21a303c8281a4e4083944b1fc7e72d2f",
            "value": 0
          }
        },
        "d1ba75e2a00747e0b66e8ddcdc6efe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e28082b69a5f4362894268fc2598d33d",
              "IPY_MODEL_d43ad895dfdd48db8493f255736d136e",
              "IPY_MODEL_2c2c576888aa43e8b1d661128c6becc9"
            ],
            "layout": "IPY_MODEL_7644321972284fcabc17109951971908"
          }
        },
        "d43ad895dfdd48db8493f255736d136e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37dfd588a6d8489eb7698699cb13c764",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f26e78e201b84f479b4e8c6f13e1dc9a",
            "value": 241627721
          }
        },
        "d4563ba8057844499e226f0b7ef8367d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28082b69a5f4362894268fc2598d33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e308ccdd6cb74624a2ef6415ed708202",
            "placeholder": "​",
            "style": "IPY_MODEL_d4563ba8057844499e226f0b7ef8367d",
            "value": "100%"
          }
        },
        "e308ccdd6cb74624a2ef6415ed708202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e664ae4f7de14a02bb342bb7c0c0b8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae552726e3f24af2afe28cb6136cbbc3",
              "IPY_MODEL_b3b67399338b47109c3e8dd874c5c78a",
              "IPY_MODEL_9c63711cfcff460398a7e4a5be6a3e79"
            ],
            "layout": "IPY_MODEL_69b22b288b024493b40f8713681801ae"
          }
        },
        "ef53e30a01eb422086accebafce47bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26e78e201b84f479b4e8c6f13e1dc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
